{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n#import kaggle_evaluation.mcts_inference_server\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n\ndf = pd.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\",\n                low_memory=False)\nconcepts = pd.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/concepts.csv\",\n                low_memory=False)\ntest = pd.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\",\n                low_memory=False)\nsample_submission = pd.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\",\n                low_memory=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-19T13:24:41.292030Z","iopub.execute_input":"2024-09-19T13:24:41.292532Z","iopub.status.idle":"2024-09-19T13:25:56.109422Z","shell.execute_reply.started":"2024-09-19T13:24:41.292491Z","shell.execute_reply":"2024-09-19T13:25:56.108090Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/concepts.csv\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/mcts_gateway.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/__init__.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/mcts_inference_server.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/templates.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/relay.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/__init__.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/um-game-playing-strength-of-mcts-variants/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_data(df):\n    \"\"\"\n    Performs transformations on df and returns transformed df.\n    \"\"\"\n    # Convert integer columns to float\n    int_columns = df.select_dtypes(include='int').columns\n    df[int_columns] = df[int_columns].astype(float)\n\n    # Initialize a list to store columns to drop\n    columns_to_drop = []\n\n    # Iterate over columns and their content\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum() == len(content):  # Entire column is NaN\n                print(f\"Column '{label}' is entirely NaN, dropping it.\")\n                columns_to_drop.append(label)\n        else:\n            if pd.isnull(content).sum() == len(content):  # Entire column is NaN\n                print(f\"Column '{label}' is entirely NaN, dropping it.\")\n                columns_to_drop.append(label)\n\n    # Drop the columns that are entirely NaN\n    df.drop(columns=columns_to_drop, inplace=True)\n\n    return df\n\n# Turn categorical variables data into numbers and fill messing\ndef encode_categories(df):\n    label_encoder = LabelEncoder()\n    for label, content in df.items():\n        if not pd.api.types.is_numeric_dtype(content):\n            df[label] = label_encoder.fit_transform(df[label])\n    return df\n\n# *Normalization and standardization*\ndef scale_data(df):\n    # Create a StandardScaler object\n    scaler = StandardScaler()\n    # Apply standardization to numeric columns and convert back to DataFrame\n    df_scaled = scaler.fit_transform(df)\n\n    # Convert the NumPy array back to a DataFrame, retaining the original column names\n    df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n\n    return df_scaled\n\n# a function that receive a df and split out data into training/validation sets\ndef split(df):\n    # Sample data (features and target)\n    X = df.drop(columns=['utility_agent1', 'Id'])  # Features\n    y = df['utility_agent1']               # Target\n\n    # Split the data into training and validation sets\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Optionally, you can print the shapes to verify the split\n    print(f\"Training data shape: {X_train.shape}, Validation data shape: {X_val.shape}\")\n    print(f\"Training target shape: {y_train.shape}, Validation target shape: {y_val.shape}\")\n    \n    return X_train, X_val, y_train, y_val\n\n\n# Process the training data\ndf = preprocess_data(df)    \ndf = encode_categories(df)\ndf_scaled = scale_data(df)\n\nX_train, X_val, y_train, y_val = split(df)\n#X_train, X_val, y_train, y_val = split(df_scaled)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:27:29.641561Z","iopub.execute_input":"2024-09-19T13:27:29.642124Z","iopub.status.idle":"2024-09-19T13:27:40.413186Z","shell.execute_reply.started":"2024-09-19T13:27:29.642078Z","shell.execute_reply":"2024-09-19T13:27:40.411418Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Training data shape: (186587, 794), Validation data shape: (46647, 794)\nTraining target shape: (186587,), Validation target shape: (46647,)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:28:08.155780Z","iopub.execute_input":"2024-09-19T13:28:08.156282Z","iopub.status.idle":"2024-09-19T13:28:08.164144Z","shell.execute_reply.started":"2024-09-19T13:28:08.156240Z","shell.execute_reply":"2024-09-19T13:28:08.162934Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"(233234, 796)"},"metadata":{}}]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:28:08.929919Z","iopub.execute_input":"2024-09-19T13:28:08.930402Z","iopub.status.idle":"2024-09-19T13:28:08.937817Z","shell.execute_reply.started":"2024-09-19T13:28:08.930355Z","shell.execute_reply":"2024-09-19T13:28:08.936568Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"(3, 810)"},"metadata":{}}]},{"cell_type":"code","source":"# Modeling\n# Fit the model on the best found hyperparameters\n\nbest_params = {\n    'n_estimators': 20,\n    'min_samples_split': 18,\n    'min_samples_leaf': 1,\n    'max_samples': 10000,\n    'max_features': None,\n    'max_depth': None\n}\n\n# Instantiate the model with the best hyperparameters\nbest_rf_model = RandomForestRegressor(\n    n_estimators=best_params['n_estimators'],\n    min_samples_split=best_params['min_samples_split'],\n    min_samples_leaf=best_params['min_samples_leaf'],\n    max_samples=best_params['max_samples'],\n    max_features=best_params['max_features'],\n    max_depth=best_params['max_depth'],\n    n_jobs=-1,\n    random_state=42\n)\n\n# Fit the model to the training data\nbest_rf_model.fit(X_train, y_train)\n\n\n\n\n\n## Training Evaluation\ndef rmsle(y_test, y_preds):\n    # Add a small constant to avoid taking the log of zero\n    y_test = np.maximum(y_test, 0)\n    y_preds = np.maximum(y_preds, 0)\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n\ndef show_scores(model):\n    train_preds = model.predict(X_train)\n    valid_preds = model.predict(X_val)\n    scores = {\n        \"Training MAE\": mean_absolute_error(y_train, train_preds),\n        \"Valid MAE\": mean_absolute_error(y_val, valid_preds),\n        \"Training RMSLE\": rmsle(y_train, train_preds),\n        \"Valid RMSLE\": rmsle(y_val, valid_preds),\n        \"Training R2\": r2_score(y_train, train_preds),\n        \"Valid R2\": r2_score(y_val, valid_preds)\n    }\n    return scores\n\nshow_scores(best_rf_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:28:11.454740Z","iopub.execute_input":"2024-09-19T13:28:11.455247Z","iopub.status.idle":"2024-09-19T13:28:21.596062Z","shell.execute_reply.started":"2024-09-19T13:28:11.455201Z","shell.execute_reply":"2024-09-19T13:28:21.594708Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"{'Training MAE': 0.0006497250222094305,\n 'Valid MAE': 0.0006807145440770274,\n 'Training RMSLE': 0.0038681119386722454,\n 'Valid RMSLE': 0.004422532266769469,\n 'Training R2': 0.9998573848346392,\n 'Valid R2': 0.9998425866787627}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"markdown","source":"*now i have my model trained\n\n> i will preprocess the test data\n\n> then add to it the unavailable labels\n\n> then make prediction on it*","metadata":{}},{"cell_type":"code","source":"'''find the median of the 3 columns \n- num_draws_agent1\n- num_losses_agent1\n- num_wins_agent1\n\nthen fill the test file with the medians by creating new columns''' \n\n# Calculate the median values for the missing labels\nmedian_wins = df['num_wins_agent1'].median()\nmedian_draws = df['num_draws_agent1'].median()\nmedian_losses = df['num_losses_agent1'].median()\n\n# Create the columns and fill with median values from the training data\ntest['num_wins_agent1'] = median_wins\ntest['num_draws_agent1'] = median_draws\ntest['num_losses_agent1'] = median_losses\n\n# Process the test data\nX_test = preprocess_data(test)    \nX_test = encode_categories(test)\n\n# Extract the 'Id' column from X_test and store it\nId = X_test['Id']\n\n# Drop the 'Id' column from X_test\nX_test = X_test.drop(columns=['Id'])","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:28:21.598498Z","iopub.execute_input":"2024-09-19T13:28:21.598945Z","iopub.status.idle":"2024-09-19T13:28:21.879170Z","shell.execute_reply.started":"2024-09-19T13:28:21.598895Z","shell.execute_reply":"2024-09-19T13:28:21.877946Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Column 'Behaviour' is entirely NaN, dropping it.\nColumn 'StateRepetition' is entirely NaN, dropping it.\nColumn 'Duration' is entirely NaN, dropping it.\nColumn 'Complexity' is entirely NaN, dropping it.\nColumn 'BoardCoverage' is entirely NaN, dropping it.\nColumn 'GameOutcome' is entirely NaN, dropping it.\nColumn 'StateEvaluation' is entirely NaN, dropping it.\nColumn 'Clarity' is entirely NaN, dropping it.\nColumn 'Decisiveness' is entirely NaN, dropping it.\nColumn 'Drama' is entirely NaN, dropping it.\nColumn 'MoveEvaluation' is entirely NaN, dropping it.\nColumn 'StateEvaluationDifference' is entirely NaN, dropping it.\nColumn 'BoardSitesOccupied' is entirely NaN, dropping it.\nColumn 'BranchingFactor' is entirely NaN, dropping it.\nColumn 'DecisionFactor' is entirely NaN, dropping it.\nColumn 'MoveDistance' is entirely NaN, dropping it.\nColumn 'PieceNumber' is entirely NaN, dropping it.\nColumn 'ScoreDifference' is entirely NaN, dropping it.\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test.shape, X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:35:23.579709Z","iopub.execute_input":"2024-09-19T13:35:23.580207Z","iopub.status.idle":"2024-09-19T13:35:23.588134Z","shell.execute_reply.started":"2024-09-19T13:35:23.580165Z","shell.execute_reply":"2024-09-19T13:35:23.586731Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"((3, 794), (186587, 794))"},"metadata":{}}]},{"cell_type":"code","source":"# Load the sample_submission.csv file provided by Kaggle\nsample_submission = pd.read_csv('/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv')\n\n# Generate predictions\ny_pred = best_rf_model.predict(X_test)\n\n# Limit the predictions between -1 and 1 to meet the competition requirements\ny_pred = np.clip(y_pred, -1.0, 1.0)\n\n# Replace the 'utility_agent1' column with the predictions\nsample_submission['utility_agent1'] = y_pred  \n\n# Export the predictions to a CSV file for submission\nsample_submission.to_csv('sample_submission.csv', index=False)\n\nprint(\"Submission file successfully exported with the name 'submission.parquet'\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:37:46.532062Z","iopub.execute_input":"2024-09-19T13:37:46.532541Z","iopub.status.idle":"2024-09-19T13:37:46.597160Z","shell.execute_reply.started":"2024-09-19T13:37:46.532500Z","shell.execute_reply":"2024-09-19T13:37:46.595954Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"Submission file successfully exported with the name 'submission.parquet'\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:37:55.328642Z","iopub.execute_input":"2024-09-19T13:37:55.329096Z","iopub.status.idle":"2024-09-19T13:37:55.341183Z","shell.execute_reply.started":"2024-09-19T13:37:55.329055Z","shell.execute_reply":"2024-09-19T13:37:55.339775Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"       Id  utility_agent1\n0  233234       -0.003333\n1  233235       -0.003333\n2  233236       -0.003333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>utility_agent1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>233234</td>\n      <td>-0.003333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>233235</td>\n      <td>-0.003333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>233236</td>\n      <td>-0.003333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}